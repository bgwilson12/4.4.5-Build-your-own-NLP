{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\bretw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "bible = gutenberg.raw('bible-kjv.txt')\n",
    "    \n",
    "bible = text_cleaner(bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>King James Bible</th>\n",
       "      <th>Vulgate</th>\n",
       "      <th>Douay Rheims</th>\n",
       "      <th>Full title in the Authorised Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Exodus</td>\n",
       "      <td>Exodus</td>\n",
       "      <td>Exodus</td>\n",
       "      <td>The Second Book of Moses, called Exodus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Leviticus</td>\n",
       "      <td>Leviticus</td>\n",
       "      <td>Leviticus</td>\n",
       "      <td>The Third Book of Moses, called Leviticus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Numbers</td>\n",
       "      <td>Numeri</td>\n",
       "      <td>Numbers</td>\n",
       "      <td>The Fourth Book of Moses, called Numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Deuteronomy</td>\n",
       "      <td>Deuteronomium</td>\n",
       "      <td>Deuteronomy</td>\n",
       "      <td>The Fifth Book of Moses, called Deuteronomy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index King James Bible        Vulgate Douay Rheims  \\\n",
       "0      0          Genesis        Genesis      Genesis   \n",
       "1      1           Exodus         Exodus       Exodus   \n",
       "2      2        Leviticus      Leviticus    Leviticus   \n",
       "3      3          Numbers         Numeri      Numbers   \n",
       "4      4      Deuteronomy  Deuteronomium  Deuteronomy   \n",
       "\n",
       "          Full title in the Authorised Version  \n",
       "0      The First Book of Moses, called Genesis  \n",
       "1      The Second Book of Moses, called Exodus  \n",
       "2    The Third Book of Moses, called Leviticus  \n",
       "3     The Fourth Book of Moses, called Numbers  \n",
       "4  The Fifth Book of Moses, called Deuteronomy  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull the titles of all the books off of wikipedia\n",
    "bible_wikipedia_df = pd.read_html('https://en.wikipedia.org/wiki/List_of_books_of_the_King_James_Version', header=0)\n",
    "\n",
    "bible_titles_df = bible_wikipedia_df[0].append(bible_wikipedia_df[2])\n",
    "\n",
    "print(len(bible_titles_df))\n",
    "bible_titles_df.reset_index(inplace=True)\n",
    "bible_titles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each book at the beginning of the text\n",
    "bible_texts = bible.split(' 1:1 ')\n",
    "\n",
    "# Get rid of the title\n",
    "bible_texts = bible_texts[1:]\n",
    "\n",
    "# This will cut out the titles of each book from the end of the text. Mostly accurate.\n",
    "for i, title in enumerate(bible_titles_df.iloc[1:, -1]):\n",
    "    to_cut = len(title)\n",
    "    bible_texts[i] = bible_texts[i][:-to_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to cut out all of the passage numbers.\n",
    "for i, book in enumerate(bible_texts):\n",
    "    bible_texts[i] = re.sub(r'\\d+\\:\\d+', '', book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bible_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "bible_doc = []\n",
    "for book in bible_texts:\n",
    "    bible_doc.append(nlp(book))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(In, the, beginning, God, created, the, heaven...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(And, the, earth, was, without, form, ,, and, ...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(And, the, Spirit, of, God, moved, upon, the, ...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(And, God, said, ,, Let, there, be, light, :, ...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(And, God, saw, the, light, ,, that, it, was, ...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  (In, the, beginning, God, created, the, heaven...   \n",
       "1  (And, the, earth, was, without, form, ,, and, ...   \n",
       "2  (And, the, Spirit, of, God, moved, upon, the, ...   \n",
       "3  (And, God, said, ,, Let, there, be, light, :, ...   \n",
       "4  (And, God, saw, the, light, ,, that, it, was, ...   \n",
       "\n",
       "                                         1  \n",
       "0  The First Book of Moses, called Genesis  \n",
       "1  The First Book of Moses, called Genesis  \n",
       "2  The First Book of Moses, called Genesis  \n",
       "3  The First Book of Moses, called Genesis  \n",
       "4  The First Book of Moses, called Genesis  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_sents = []\n",
    "for i, title in enumerate(bible_titles_df.iloc[:, -1]):\n",
    "    bible_sents.extend([[sent, title] for sent in bible_doc[i].sents])\n",
    "\n",
    "# Create our dataframe\n",
    "sentences_all = pd.DataFrame(bible_sents)\n",
    "sentences_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The Book of Psalms                                                            2730\n",
       "The First Book of Moses, called Genesis                                       1780\n",
       "The Book of the Prophet Jeremiah                                              1559\n",
       "The Book of the Prophet Isaiah                                                1535\n",
       "The Book of the Prophet Ezekiel                                               1356\n",
       "The Gospel According to St. Luke                                              1315\n",
       "The Second Book of Moses, called Exodus                                       1301\n",
       "The Gospel According to St. Matthew                                           1216\n",
       "The Fourth Book of Moses, called Numbers                                      1211\n",
       "The Book of Job                                                               1133\n",
       "The First Book of Samuel, otherwise called the First Book of the Kings        1112\n",
       "The Gospel According to St. John                                              1100\n",
       "The Acts of the Apostles                                                      1042\n",
       "The Second Book of the Kings, commonly called the Fourth Book of the Kings     991\n",
       "The First Book of the Kings, commonly called the Third Book of the Kings       975\n",
       "The Second Book of Samuel, otherwise called the Second Book of the Kings       943\n",
       "The Fifth Book of Moses, called Deuteronomy                                    925\n",
       "The Second Book of the Chronicles                                              923\n",
       "The Proverbs                                                                   923\n",
       "The First Book of the Chronicles                                               890\n",
       "The Third Book of Moses, called Leviticus                                      841\n",
       "The Gospel According to St. Mark                                               819\n",
       "The Book of Judges                                                             803\n",
       "The Book of Joshua                                                             591\n",
       "The First Epistle of Paul the Apostle to the Corinthians                       528\n",
       "The Epistle of Paul the Apostle to the Romans                                  504\n",
       "The Revelation of St. John the Divine                                          454\n",
       "The Book of Nehemiah                                                           396\n",
       "The Book of Daniel                                                             386\n",
       "The Epistle of Paul the Apostle to the Hebrews                                 275\n",
       "                                                                              ... \n",
       "Amos                                                                           174\n",
       "The Lamentations of Jeremiah                                                   171\n",
       "The Epistle of Paul to the Galatians                                           153\n",
       "The Song of Solomon                                                            150\n",
       "Micah                                                                          139\n",
       "The First Epistle General of John                                              135\n",
       "The General Epistle of James                                                   131\n",
       "The Book of Ruth                                                               118\n",
       "The Epistle of Paul the Apostle to the Ephesians                               102\n",
       "The First Epistle of Paul the Apostle to Timothy                               101\n",
       "Malachi                                                                         99\n",
       "The Epistle of Paul the Apostle to the Philippians                              95\n",
       "The First Epistle General of Peter                                              92\n",
       "The First Epistle of Paul the Apostle to the Thessalonians                      80\n",
       "Joel                                                                            77\n",
       "The Second Epistle of Paul the Apostle to Timothy                               75\n",
       "Habakkuk                                                                        73\n",
       "The Epistle of Paul the Apostle to the Colossians                               73\n",
       "Jonah                                                                           61\n",
       "Zephaniah                                                                       59\n",
       "Nahum                                                                           57\n",
       "The Second Epistle General of Peter                                             49\n",
       "The Second Epistle of Paul the Apostle to the Thessalonians                     42\n",
       "Haggai                                                                          37\n",
       "The Epistle of Paul to Titus                                                    36\n",
       "The General Epistle of Jude                                                     24\n",
       "Obadiah                                                                         22\n",
       "The Epistle of Paul to Philemon                                                 18\n",
       "The Third Epistle of John                                                       17\n",
       "The Second Epistle of John                                                      17\n",
       "Name: 1, Length: 66, dtype: int64"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_all.iloc[:, 1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5703\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Terah, an, hundred, and, nineteen, years, ,, ...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(therefore, ,, behold, ,, also, his, blood, is...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Now, therefore, take, ,, I, pray, thee, ,, th...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(And, it, came, to, pass, on, the, third, day,...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(And, the, LORD, said, unto, Noah, ,, Come, th...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  (Terah, an, hundred, and, nineteen, years, ,, ...   \n",
       "1  (therefore, ,, behold, ,, also, his, blood, is...   \n",
       "2  (Now, therefore, take, ,, I, pray, thee, ,, th...   \n",
       "3  (And, it, came, to, pass, on, the, third, day,...   \n",
       "4  (And, the, LORD, said, unto, Noah, ,, Come, th...   \n",
       "\n",
       "                                         1  \n",
       "0  The First Book of Moses, called Genesis  \n",
       "1  The First Book of Moses, called Genesis  \n",
       "2  The First Book of Moses, called Genesis  \n",
       "3  The First Book of Moses, called Genesis  \n",
       "4  The First Book of Moses, called Genesis  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = pd.DataFrame()\n",
    "\n",
    "# This loop reduces the size of our dataset by randomly picking 100 sentences from each book\n",
    "# of the bible. If there are less than 100 books, then all of the books are kept in the dataset\n",
    "for title in bible_titles_df.iloc[:, -1]:\n",
    "    subset_by_title = sentences_all[sentences_all.iloc[:, 1] == title]\n",
    "    subset_idx = subset_by_title.index\n",
    "    if len(subset_idx) <= 100:\n",
    "        sentences = sentences.append(subset_by_title)\n",
    "    else:\n",
    "        random_indices = np.random.choice(subset_idx, 100, replace=False).tolist()\n",
    "        sentences = sentences.append(subset_by_title.loc[random_indices, :])\n",
    "        \n",
    "sentences.reset_index(inplace=True, drop=True)\n",
    "print(len(sentences))\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    n = len(df)\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            clear_output()\n",
    "            print(\"Processing row {}/{}\".format(i, n))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up bag the bags.\n",
    "bible_words = []\n",
    "for book in bible_doc:\n",
    "    bible_words.extend(bag_of_words(book))\n",
    "    \n",
    "common_words = set(bible_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a ton of sentences in this dataset, about as many as the Alice and Persuasion datasets. However, we have 7000 features instead of however many those ones had. So, I'm going to take a subset of our data because this is taking far too long to run. I'm not a very patient person unfortunately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 5700/5703\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oblation</th>\n",
       "      <th>oil</th>\n",
       "      <th>proper</th>\n",
       "      <th>dasheth</th>\n",
       "      <th>sink</th>\n",
       "      <th>gaba</th>\n",
       "      <th>zelophehad</th>\n",
       "      <th>slanderer</th>\n",
       "      <th>saving</th>\n",
       "      <th>copper</th>\n",
       "      <th>...</th>\n",
       "      <th>ulai</th>\n",
       "      <th>drop</th>\n",
       "      <th>uncorruptness</th>\n",
       "      <th>lantern</th>\n",
       "      <th>uz</th>\n",
       "      <th>partly</th>\n",
       "      <th>bridechamber</th>\n",
       "      <th>assuredly</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Terah, an, hundred, and, nineteen, years, ,, ...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(therefore, ,, behold, ,, also, his, blood, is...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Now, therefore, take, ,, I, pray, thee, ,, th...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(And, it, came, to, pass, on, the, third, day,...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(And, the, LORD, said, unto, Noah, ,, Come, th...</td>\n",
       "      <td>The First Book of Moses, called Genesis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  oblation oil proper dasheth sink gaba zelophehad slanderer saving copper  \\\n",
       "0        0   0      0       0    0    0          0         0      0      0   \n",
       "1        0   0      0       0    0    0          0         0      0      0   \n",
       "2        0   0      0       0    0    0          0         0      0      0   \n",
       "3        0   0      0       0    0    0          0         0      0      0   \n",
       "4        0   0      0       0    0    0          0         0      0      0   \n",
       "\n",
       "                    ...                    ulai drop uncorruptness lantern uz  \\\n",
       "0                   ...                       0    0             0       0  0   \n",
       "1                   ...                       0    0             0       0  0   \n",
       "2                   ...                       0    0             0       0  0   \n",
       "3                   ...                       0    0             0       0  0   \n",
       "4                   ...                       0    0             0       0  0   \n",
       "\n",
       "  partly bridechamber assuredly  \\\n",
       "0      0            0         0   \n",
       "1      0            0         0   \n",
       "2      0            0         0   \n",
       "3      0            0         0   \n",
       "4      0            0         0   \n",
       "\n",
       "                                       text_sentence  \\\n",
       "0  (Terah, an, hundred, and, nineteen, years, ,, ...   \n",
       "1  (therefore, ,, behold, ,, also, his, blood, is...   \n",
       "2  (Now, therefore, take, ,, I, pray, thee, ,, th...   \n",
       "3  (And, it, came, to, pass, on, the, third, day,...   \n",
       "4  (And, the, LORD, said, unto, Noah, ,, Come, th...   \n",
       "\n",
       "                               text_source  \n",
       "0  The First Book of Moses, called Genesis  \n",
       "1  The First Book of Moses, called Genesis  \n",
       "2  The First Book of Moses, called Genesis  \n",
       "3  The First Book of Moses, called Genesis  \n",
       "4  The First Book of Moses, called Genesis  \n",
       "\n",
       "[5 rows x 7277 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_counts.iloc[:, -2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no default __reduce__ due to non-trivial __cinit__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-260-ffb717f670f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word_counts.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'word_counts_sentences.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\toolkits.win\\anaconda3-4.4.0\\lib\\site-packages\\spacy\\tokens\\span.cp36-win_amd64.pyd\u001b[0m in \u001b[0;36mspacy.tokens.span.Span.__reduce_cython__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no default __reduce__ due to non-trivial __cinit__"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(word_counts.iloc[:, :-2], open('word_counts.pkl', 'wb'))\n",
    "pickle.dump(word_counts.iloc[:, -2], open('word_counts_sentences.pkl', 'wb'))\n",
    "pickle.dump(word_counts.ilov[:, -1], open('word_counts_source.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34451"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bible_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9856767027185034\n",
      "\n",
      "Test set score: 0.1691498685363716\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26292725679228746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "mnb = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "# score = f1_score(y_test, bnb.predict(X_test), pos_label='Carroll')\n",
    "print(mnb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF and LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 : 24 And God said , Let the earth bring forth the living creature after his kind , cattle , and creeping thing , and beast of the earth after his kind : and it was so .'"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This time, download as paragraphs and append lsa to all variables\n",
    "bible_lsa = gutenberg.paras('bible-kjv.txt')\n",
    "bible_paras = []\n",
    "for paragraph in bible_lsa:\n",
    "    para = paragraph[0]\n",
    "    bible_paras.append(' '.join(para))\n",
    "\n",
    "bible_paras = bible_paras[2:]\n",
    "bible_paras[22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't want to get rid of all of the preprocessing steps I did earlier so I'm going to try a different way than the curriculum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And God said , Let the waters bring forth abundantly the moving creature that hath life , and fowl that may fly above the earth in the open firmament of heaven .'"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_paras = []\n",
    "for line in sentences_all.iloc[:, 0]:\n",
    "    word = []\n",
    "    sentence = []\n",
    "    for char in line:\n",
    "        \n",
    "        if not char.is_punct:\n",
    "            word.append(str(char))\n",
    "        else:\n",
    "            sentence.extend(word)\n",
    "            sentence.append(str(char))\n",
    "            word = []\n",
    "    sentence = ' '.join((sentence))\n",
    "    bible_paras.append(sentence)\n",
    "bible_paras[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34451"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bible_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 8242\n",
      "Original sentence: The fear of the LORD is the instruction of wisdom ; and before honour is humility .\n",
      "Tf_idf vector: {'humility': 0.5723592077667204, 'instruction': 0.4857792434425227, 'wisdom': 0.3698689200583855, 'honour': 0.4001605824061108, 'fear': 0.33679858562859644, 'lord': 0.16142697081617147}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bible_paras, sentences_all.iloc[:, 1], test_size=0.8, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "bible_paras_tfidf = vectorizer.fit_transform(bible_paras)\n",
    "print(\"Number of features: %d\" % bible_paras_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(bible_paras_tfidf, sentences_all.iloc[:, 1], test_size=0.8, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_train[5])\n",
    "print('Tf_idf vector:', tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6890, 230)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_lsa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6890"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 39.35157927550453\n",
      "Component 0:\n",
      "And they shall hearken to thy voice : and thou shalt come , thou and the elders of Israel , unto the king of Egypt , and ye shall say unto him , The LORD God of the Hebrews hath met with us : and now let us go , we beseech thee , three days ' journey into the wilderness , that we may sacrifice to the LORD our God .                                                                                                                      0.652141\n",
      "But thou , O LORD , shall endure for ever ; and thy remembrance unto all generations .                                                                                                                                                                                                                                                                                                                                                            0.648153\n",
      "And it shall be when the LORD shall bring thee into the land of the Canaanites , as he sware unto thee and to thy fathers , and shall give it thee ,   That thou shalt set apart unto the LORD all that openeth the matrix , and every firstling that cometh of a beast which thou hast ; the males shall be the LORD 's .                                                                                                                        0.639849\n",
      "And it shall come to pass , when the LORD shall have done to my lord according to all the good that he hath spoken concerning thee , and shall have appointed thee ruler over Israel ;   That this shall be no grief unto thee , nor offence of heart unto my lord , either that thou hast shed blood causeless , or that my lord hath avenged himself : but when the LORD shall have dealt well with my lord , then remember thine handmaid .    0.629057\n",
      "But unto the place which the LORD your God shall choose out of all your tribes to put his name there , even unto his habitation shall ye seek , and thither thou shalt come :                                                                                                                                                                                                                                                                     0.590795\n",
      "And the LORD said unto him ,                                                                                                                                                                                                                                                                                                                                                                                                                      0.588986\n",
      "Therefore thou shalt speak unto them this word ; Thus saith the LORD God of Israel , Every bottle shall be filled with wine : and they shall say unto thee , Do we not certainly know that every bottle shall be filled with wine ?                                                                                                                                                                                                               0.586591\n",
      "shall be deliverance , as the LORD hath said , and in the remnant whom the LORD shall call .                                                                                                                                                                                                                                                                                                                                                      0.585106\n",
      "And the LORD said furthermore unto him ,                                                                                                                                                                                                                                                                                                                                                                                                          0.583648\n",
      "And the LORD said unto him , Wherewith ?                                                                                                                                                                                                                                                                                                                                                                                                          0.580972\n",
      "Name: 0, dtype: float64\n",
      "Component 1:\n",
      "And it shall be ,                                   0.722550\n",
      "shall I resemble it ?                               0.722550\n",
      "Whither shall we go up ?                            0.722550\n",
      "I have put off my coat ; how shall I put it on ?    0.715814\n",
      "They shall go hindmost with their standards .       0.714166\n",
      "shall I overtake them ?                             0.712474\n",
      "I shall drive them .                                0.707320\n",
      "And Hazor shall be a dwelling for dragons ,         0.695894\n",
      ": it shall not go out in the jubile .               0.688351\n",
      "And they shall go forward in the third rank .       0.675548\n",
      "Name: 1, dtype: float64\n",
      "Component 2:\n",
      "Behind the doors also and the posts hast thou set up thy remembrance : for thou hast discovered thyself to another than me , and art gone up ; thou hast enlarged thy bed , and made thee a covenant with them ; thou lovedst their bed where thou sawest it .                   0.691939\n",
      "And when thou sendest him out free from thee , thou shalt not let him go away empty :   Thou shalt furnish him liberally out of thy flock , and out of thy floor , and out of thy winepress : of that wherewith the LORD thy God hath blessed thee thou shalt give unto him .    0.691352\n",
      ", I forgave thee all that debt , because thou desiredst me :   Shouldest not thou also have had compassion on thy fellowservant , even as I had pity on thee ?                                                                                                                   0.678326\n",
      "When thou comest into thy neighbour 's vineyard , then thou mayest eat grapes thy fill at thine own pleasure ; but thou shalt not put any in thy vessel .                                                                                                                        0.664413\n",
      "Thou also , which hast judged thy sisters , bear thine own shame for thy sins that thou hast committed more abominable than they : they are more righteous than thou : yea , be thou confounded also , and bear thy shame , in that thou hast justified thy sisters .            0.657624\n",
      "Cursed shalt thou be when thou comest in , and cursed shalt thou be when thou goest out .                                                                                                                                                                                        0.648483\n",
      "Thou shalt not abhor an Edomite ; for he is thy brother : thou shalt not abhor an Egyptian ; because thou wast a stranger in his land .                                                                                                                                          0.646017\n",
      "What meanest thou by these ?                                                                                                                                                                                                                                                     0.645098\n",
      "and why eatest thou not ?                                                                                                                                                                                                                                                        0.644726\n",
      ", she is thy sister , thou shalt not uncover her nakedness .                                                                                                                                                                                                                     0.634801\n",
      "Name: 2, dtype: float64\n",
      "Component 3:\n",
      "I am the LORD their God .                                                                                                                                                     0.636973\n",
      "I am the LORD your God .                                                                                                                                                      0.636973\n",
      "O LORD :                                                                                                                                                                      0.566480\n",
      "Give them , O LORD :                                                                                                                                                          0.566480\n",
      "I am the LORD .                                                                                                                                                               0.566480\n",
      "O Lord ,                                                                                                                                                                      0.566480\n",
      "Help me , O LORD my God :                                                                                                                                                     0.558666\n",
      "God is jealous , and the LORD revengeth ; the LORD revengeth , and is furious ; the LORD will take vengeance on his adversaries , and he reserveth wrath for his enemies .    0.548286\n",
      "For who is God , save the LORD ?                                                                                                                                              0.540253\n",
      "Do we provoke the Lord to jealousy ?                                                                                                                                          0.537766\n",
      "Name: 3, dtype: float64\n",
      "Component 4:\n",
      "and ye have snuffed at it ,                                                                                                                       0.866061\n",
      "What will ye see in the Shulamite ?                                                                                                               0.866058\n",
      "ye accuse him :                                                                                                                                   0.862343\n",
      "Against whom do ye sport yourselves ?                                                                                                             0.862267\n",
      "Why do ye not rather take wrong ?                                                                                                                 0.858117\n",
      "How many loaves have ye ?                                                                                                                         0.854005\n",
      "will ye render me a recompence ?                                                                                                                  0.851619\n",
      "Now therefore perform the doing of it ; that as there was a readiness to will , so there may be a performance also out of that which ye have .    0.847937\n",
      "So run , that ye may obtain .                                                                                                                     0.837627\n",
      "Ye serpents , ye generation of vipers , how can ye escape the damnation of hell ?                                                                 0.833602\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
    "svd= TruncatedSVD(230)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "#Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=X_train)\n",
    "for i in range(5):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9692307692307692\n",
      "Testing score:  0.15844853234643155\n"
     ]
    }
   ],
   "source": [
    "rfc_lsa = ensemble.RandomForestClassifier().fit(X_train_lsa, y_train_tfidf)\n",
    "print('Training score: ', rfc_lsa.score(X_train_lsa, y_train_tfidf))\n",
    "print('Testing score: ', rfc_lsa.score(X_test_lsa, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9693759071117561\n",
      "Testing score:  0.263197997169914\n"
     ]
    }
   ],
   "source": [
    "rfc_tfidf = ensemble.RandomForestClassifier().fit(X_train_tfidf, y_train_tfidf)\n",
    "print('Training score: ', rfc_tfidf.score(X_train_tfidf, y_train_tfidf))\n",
    "print('Testing score: ', rfc_tfidf.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.5031930333817126\n",
      "Testing score:  0.30742716156888356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "lsvm_lsa = LinearSVC().fit(X_train_lsa, y_train_tfidf)\n",
    "print('Training score: ', lsvm_lsa.score(X_train_lsa, y_train_tfidf))\n",
    "print('Testing score: ', lsvm_lsa.score(X_test_lsa, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9686502177068215\n",
      "Testing score:  0.2536192445847393\n"
     ]
    }
   ],
   "source": [
    "lsvm_tfidf = ensemble.RandomForestClassifier().fit(X_train_tfidf, y_train_tfidf)\n",
    "print('Training score: ', lsvm_tfidf.score(X_train_tfidf, y_train_tfidf))\n",
    "print('Testing score: ', lsvm_tfidf.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.43149492017416546\n",
      "Testing score:  0.18794673633032183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_lsa = KNeighborsClassifier().fit(X_train_lsa, y_train_tfidf)\n",
    "print('Training score: ', knn_lsa.score(X_train_lsa, y_train_tfidf))\n",
    "print('Testing score: ', knn_lsa.score(X_test_lsa, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.3478955007256894\n",
      "Testing score:  0.08185479481876565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_tfidf = KNeighborsClassifier().fit(X_train_tfidf, y_train_tfidf)\n",
    "print('Training score: ', knn_tfidf.score(X_train_tfidf, y_train_tfidf))\n",
    "print('Testing score: ', knn_tfidf.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.08171262699564587\n",
      "Testing score:  0.07862559413664236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_lsa = SVC().fit(X_train_lsa, y_train_tfidf)\n",
    "print('Training score: ', svc_lsa.score(X_train_lsa, y_train_tfidf))\n",
    "print('Testing score: ', svc_lsa.score(X_test_lsa, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.08171262699564587\n",
      "Testing score:  0.07862559413664236\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf = SVC().fit(X_train_lsa, y_train_tfidf)\n",
    "print('Training score: ', svc_tfidf.score(X_train_lsa, y_train_tfidf))\n",
    "print('Testing score: ', svc_tfidf.score(X_test_lsa, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.4011611030478955\n",
      "Testing score:  0.29770327636878197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_lsa = LogisticRegression().fit(X_train_lsa, y_train_tfidf)\n",
    "print('Training score: ', lr_lsa.score(X_train_lsa, y_train_tfidf))\n",
    "print('Testing score: ', lr_lsa.score(X_test_lsa, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.5904208998548621\n",
      "Testing score:  0.32999528319001487\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression().fit(X_train_tfidf, y_train_tfidf)\n",
    "print('Training score: ', lr_tfidf.score(X_train_tfidf, y_train_tfidf))\n",
    "print('Testing score: ', lr_tfidf.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "The best model was Logistic Regression, with an initial score of 0.32 on the test set. The last part of this assignment is to increase this score by 5%. I will be using RandomizedSearchCV to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reports the top n_top results for a random search\n",
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\toolkits.win\\anaconda3-4.4.0\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.343 (std: 0.003)\n",
      "Parameters: {'penalty': 'l2', 'C': 4.871363584092783}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.343 (std: 0.003)\n",
      "Parameters: {'penalty': 'l2', 'C': 4.833487238433598}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.343 (std: 0.003)\n",
      "Parameters: {'penalty': 'l2', 'C': 4.814000886572774}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.342 (std: 0.003)\n",
      "Parameters: {'penalty': 'l2', 'C': 4.801430041487284}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.342 (std: 0.003)\n",
      "Parameters: {'penalty': 'l2', 'C': 4.714816359662238}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {'C':np.random.uniform(3.0, 5.0, 1000),\n",
    "             'penalty':['l1', 'l2']}\n",
    "n_iter = 50\n",
    "\n",
    "log_reg_rand = LogisticRegression(class_weight='balanced')\n",
    "lr_search = RandomizedSearchCV(log_reg_rand,\n",
    "                               param_distributions=param_dist,\n",
    "                               n_iter=n_iter, n_jobs=-1)\n",
    "\n",
    "lr_search.fit(X_train_tfidf, y_train_tfidf)\n",
    "report(lr_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried \n",
    "\n",
    ":|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
